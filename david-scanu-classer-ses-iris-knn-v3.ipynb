{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classer ses iris (KNN)\n",
    "\n",
    "David Scanu \n",
    "\n",
    "* v3 - Feature Selection\n",
    "\n",
    "---\n",
    "\n",
    "## Contexte du projet\n",
    "\n",
    "Une chaine de fleuriste aimerait pouvoir trier ses différentes espèces d'iris.\n",
    "Réalisez un programme permettant de prédire l'espèce d'une iris à partir de la largeur et longueur de ses sépales et des pétales.\n",
    "\n",
    "## Modalités pédagogiques\n",
    "\n",
    "•\tTravail individuel\n",
    "•\tdeux jours de travail\n",
    "\n",
    "## Critères de performance\n",
    "\n",
    "•\tLes données ont été analysées et il existe une trace de cette analyse exploratoire dans un jupyter-notebook\n",
    "•\tUn programme qui fonctionne sans bug, et qui classifie bien les iris (vous afficherez la matrice de confusion et l'accuracy obtenus sur la base Test)\n",
    "\n",
    "## Modalités d'évaluation\n",
    "\n",
    "Revue du code avec le formateur\n",
    "\n",
    "## Livrables\n",
    "\n",
    "Dépot Github\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importer les bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris() # nd.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quel est notre Objectif ?\n",
    "\n",
    "Compte tenu de : \n",
    "- **longueur des sépales**\n",
    "- **largeur des sépales**\n",
    "- **longueur des pétales**\n",
    "- **largeur des pétales**\n",
    "  \n",
    "Classez la fleur d'iris dans l'une des trois espèces - **Setosa**, **Virginica** et **Versicolor**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convertir le nd.array en DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.c_ is the numpy concatenate function\n",
    "# which is used to concat iris['data'] and iris['target'] arrays \n",
    "# for pandas column argument: concat iris['feature_names'] list\n",
    "# and string list (in this case one string); you can make this anything you'd like..  \n",
    "# the original dataset would probably call this ['Species']\n",
    "iris_df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                     columns= iris['feature_names'] + ['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation du dataset\n",
    "# Convert target numbers to \"Iris Species\"\n",
    "def chng(target):\n",
    "    if target == 0:\n",
    "        return 'Setosa'\n",
    "    elif target == 1:\n",
    "        return 'Versicolor'\n",
    "    elif target == 2:\n",
    "        return 'Virginica'\n",
    "\n",
    "iris_df['target'] = iris_df['target'].apply(chng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns 'target'  to 'species'ArithmeticError\n",
    "iris_df = iris_df.rename(columns={\"target\": \"species\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse statistique de base\n",
    "\n",
    "### Moyennes et médianes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.groupby('species').agg(['mean', 'median'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque caractère, la moyenne et la médiane sont relativement proches, ce qui indique une distribtuion normal de la population pour chaque caractère."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ecart-type par espèces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.groupby('species').std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\") \n",
    "plt.figure(figsize=(12,10))\n",
    "plt.subplot(2,2,1)\n",
    "sns.boxplot(x='species',y='sepal length (cm)',data=iris_df)\n",
    "plt.subplot(2,2,2)\n",
    "sns.boxplot(x='species',y='sepal width (cm)',data=iris_df)\n",
    "plt.subplot(2,2,3)\n",
    "sns.boxplot(x='species',y='petal length (cm)',data=iris_df)\n",
    "plt.subplot(2,2,4)\n",
    "sns.boxplot(x='species',y='petal width (cm)',data=iris_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les points isolés qui peuvent être vus dans les boîtes à moustaches ci-dessus sont les valeurs aberrantes dans les données. Comme ceux-ci sont très peu nombreux, cela n'aurait pas d'impact significatif sur notre analyse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Violin Plot\n",
    "\n",
    "Montre la distribution des données sur plusieurs niveaux d'une (ou plusieurs) variables catégorielles (espèces de fleurs dans notre cas) de sorte que ces distributions puissent être comparées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.subplot(2,2,1)\n",
    "sns.violinplot(x='species', y='sepal length (cm)',data=iris_df)\n",
    "plt.subplot(2,2,2)\n",
    "sns.violinplot(x='species',y='sepal width (cm)',data=iris_df)\n",
    "plt.subplot(2,2,3)\n",
    "sns.violinplot(x='species',y='petal length (cm)',data=iris_df)\n",
    "plt.subplot(2,2,4)\n",
    "sns.violinplot(x='species',y='petal width (cm)',data=iris_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairplot\n",
    "\n",
    "Premier reflexe, tracer un pairplot pour mettre en évidence répartitions et corrélations.\n",
    "\n",
    "Grace au pairplot, nous pouvons mettre en évidence les caractères qui sont correlés et qui sont pertinents pour determiner la vartiété d'Iris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=iris_df, hue=\"species\", height=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse univariée\n",
    "\n",
    "Probability Density Function (PDF) & Cumulative Distribution Function (CDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_setosa = iris_df[iris_df['species'] == \"Setosa\"]\n",
    "iris_versicolor = iris_df[iris_df['species'] == \"Versicolor\"]\n",
    "iris_virginica = iris_df[iris_df['species'] == \"Virginica\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sepal length\n",
    "sns.FacetGrid(iris_df, hue=\"species\", height=5).map(sns.histplot, \"sepal length (cm)\").add_legend();\n",
    "# sepal width\n",
    "sns.FacetGrid(iris_df, hue=\"species\", height=5).map(sns.histplot, \"sepal width (cm)\").add_legend();\n",
    "# petal length\n",
    "sns.FacetGrid(iris_df, hue=\"species\", height=5).map(sns.histplot, \"petal length (cm)\").add_legend();\n",
    "# petal width\n",
    "sns.FacetGrid(iris_df, hue=\"species\", height=5).map(sns.histplot, \"petal width (cm)\").add_legend();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur le graphique 1 et 2, les répartitions se chevauchent beaucoup et ont ne peu pas réellement en déduire que la variable est determinante comme indication de la variété.\n",
    "\n",
    "Sur le graphique 3, la densité de la longueur de \"**petal length**\" semble prometteur du point de vue de la classification univariée. Les espèces **Setosa** sont bien séparées de **Versicolor** et **Virginica**, bien qu'il y ait un certain chevauchement entre **Versicolor** et **Virginica**.\n",
    "\n",
    "Sur le graphique 4, le tracé de densité de 'petal width' semble également bon. Il y a une légère intersection entre les espèces **Setosa** et **Versicolor**, tandis que le chevauchement entre **Versicolor** et **Virginica** est quelque peu similaire à celui de la longueur des pétales (Graphique 3).\n",
    "\n",
    "Pour résumer, si nous devons choisir une caractéristique pour la classification, nous choisirons la **\"petal length\"** (Graphique 3) pour distinguer les espèces.\n",
    "\n",
    "Si nous devons sélectionner deux caractéristiques, nous choisirons **'petal width'** comme deuxième caractéristique, mais encore une fois, il serait plus sage d'examiner les graphiques en paires (analyse bivariée et multivariée) pour déterminer quelles sont les deux caractéristiques les plus utiles dans classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse Bivariée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame with the ndarray from load_iris()\n",
    "iris_enc_df = pd.DataFrame(data=np.c_[iris['data'], iris['target']], columns= iris['feature_names'] + ['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tableau de correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les correlations\n",
    "iris_enc_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(iris_enc_df.corr(), annot=True, cmap='RdBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On distingue une forte correlation entre la variété d'Iris et Petal Length et Petal Width. Ces deux criters seuls suffiraient à réaliser des prédictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=iris_df, x='sepal length (cm)', y='sepal width (cm)', hue='species')\n",
    "plt.title('Sepal width by Sepal length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=iris_df, x='petal length (cm)', y='petal width (cm)', hue='species')\n",
    "plt.title('Petal Width by Petal Length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On distingue bien sur ce graphique, que les elements sont répartis sur un ligne et que le caractère 'petal width' et 'petal length' permettent de discriminer la variété d'iris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X = iris.data\n",
    "\n",
    "# Target\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VarianceThreshold\n",
    "\n",
    "Elimine les variables dont la **variance est inférieur à un certain seuil**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance des variables\n",
    "X.var(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "selector_vt = VarianceThreshold(threshold=0.2)\n",
    "selector_vt.fit(X)\n",
    "# Affiche un masque\n",
    "selector_vt.get_support()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affiche les colonnes restantes\n",
    "np.array(iris.feature_names)[selector_vt.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vt = selector_vt.transform(X)\n",
    "X_vt[:10,:] # Affiche les 10 première ligne de notre ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectKbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Retourne 2 tableaux :\n",
    "# - score test chi2, dépendance à y\n",
    "# - P values\n",
    "chi2(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_kb = SelectKBest(chi2, k=2)\n",
    "selector_kb.fit(X, y)\n",
    "selector_kb.get_support() # Retourne une seule variable/colonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['petal length (cm)', 'petal width (cm)'], dtype='<U17')"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affiche les colonnes restantes\n",
    "np.array(iris.feature_names)[selector_kb.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_col_names = list(np.array(iris.feature_names)[selector_kb.get_support()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['petal length (cm)', 'petal width (cm)']"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.3, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.7, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.1]])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_kb = selector_kb.transform(X)\n",
    "X_kb[:10] # Affiche les 10 première ligne de notre ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectFromModel\n",
    "\n",
    "Entraine un estimateur puis selectionne les **variables** les plus importantes pour cet estimateur. Compatible avec les estimateurs qui développent une fonction paramétrée *(Ne fonctionne pas avec Knn)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "selector_sfm = SelectFromModel(SGDClassifier(random_state=0), threshold='mean')\n",
    "selector_sfm.fit(X, y)\n",
    "selector_sfm.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affiche les colonnes restantes\n",
    "np.array(iris.feature_names)[selector_sfm.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sfm = selector_sfm.transform(X)\n",
    "X_sfm[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice coefficient de 3 x 4\n",
    "selector_sfm.estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le selecteur selectionne les variables > à ce chiffre\n",
    "selector_sfm.estimator_.coef_.mean(axis=0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFE + RFECV\n",
    "\n",
    "Eliminent les variables les moins importantes de façon **récursive**.\n",
    "\n",
    "Un estimateur est entrainé plusieurs fois, après chaque entrainement, des features sont éliminées sur la base de **coefficients** les plus faibles de l'estimateur.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE, RFECV\n",
    "\n",
    "selector_RFECV = RFECV(SGDClassifier(random_state=0), step=1, min_features_to_select=2, cv=5)\n",
    "selector_RFECV.fit(X, y)\n",
    "selector_RFECV.ranking_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_RFECV.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_RFECV.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affiche les colonnes restantes\n",
    "np.array(iris.feature_names)[selector_RFECV.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_RFECV = selector_RFECV.transform(X)\n",
    "X_RFECV[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparations des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nettoyage\n",
    "\n",
    "il n'y a pas de valeurs manquantes dans le jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y-a-t il des valuers manquantes ?\n",
    "print(iris_df.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des outliers avec boxplot()\n",
    "sns.set(style=\"ticks\") \n",
    "plt.figure(figsize=(12,10))\n",
    "plt.subplot(2,2,1)\n",
    "sns.boxplot(x='species',y='sepal length (cm)',data=iris_df)\n",
    "plt.subplot(2,2,2)\n",
    "sns.boxplot(x='species',y='sepal width (cm)',data=iris_df)\n",
    "plt.subplot(2,2,3)\n",
    "sns.boxplot(x='species',y='petal length (cm)',data=iris_df)\n",
    "plt.subplot(2,2,4)\n",
    "sns.boxplot(x='species',y='petal width (cm)',data=iris_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a très peu d'**outliers**. Ils ne seront pas génants pour l'entrainement de notre modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Equilibre\n",
    "\n",
    "Les cibles du jeu de données sont **bien équilibrées** puisqu'elles sont au nombre de 50 chacunes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df['species'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données contenues dans le **ndarray** récupérées avec **load_iris()** sont toutes numériques et ne nécessitent pas d'encodage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparer les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_kb, y, test_size=0.2, random_state=3)\n",
    "\n",
    "print(f\"Nombre d'exemples d'entrainement X : {X_train.shape[0]}\")\n",
    "print(f\"Nombre d'exemples de test X : {X_test.shape[0]}\")\n",
    "print(' ')\n",
    "print(f\"Nombre d'exemples d'entrainement Y : {y_train.shape[0]}\")\n",
    "print(f\"Nombre d'exemples de test Y : {y_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise à l'échelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaler = scaler.fit_transform(X_train)\n",
    "X_test_scaler = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train_minmaxscaler = min_max_scaler.fit_transform(X_train)\n",
    "X_test_minmaxscaler = min_max_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "robust_scaler = RobustScaler()\n",
    "X_train_robscaler = robust_scaler.fit_transform(X_train)\n",
    "X_test_robscaler = robust_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèle KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Nous entrainons notre modèle avec les données d'entrainements (standardisées)\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(X_train_scaler, y_train)\n",
    "print('Train Score : ', model.score(X_train_scaler, y_train))\n",
    "print('Test Score : ', model.score(X_test_scaler, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold, LeaveOneOut, ShuffleSplit, StratifiedKFold, StratifiedShuffleSplit\n",
    "from numpy import mean\n",
    "\n",
    "# Choix de la méthode de validation croisée (échantillonage)\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.5, random_state=0)\n",
    "# cv = LeaveOneOut()\n",
    "\n",
    "cross_val_res = cross_val_score(model, X_train_scaler, y_train, cv=cv, scoring='accuracy')\n",
    "print(cross_val_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_res.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation for each k value\n",
    "val_score = []\n",
    "for k in range(1, 50):\n",
    "    score = cross_val_score(KNeighborsClassifier(n_neighbors=k), X_train_scaler, y_train, cv=5).mean()\n",
    "    val_score.append(score)\n",
    "plt.plot(val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_choice(cv_list,  X_train, y_train, k_range = range(1, 20)):\n",
    "    \"\"\"Find the best cross-validation about our problems and model: K-Fold, Leave One Out, Shuffle Split, Stratified K-Fold, Group K-Fold\n",
    "    Return best CV, Max Validation Score and optimal K value. \n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"K range : \", k_range)\n",
    "\n",
    "    cv_results = {}\n",
    "\n",
    "    cv_retenu=None\n",
    "    max_val_score=0\n",
    "    k_retenu=None\n",
    "\n",
    "    for cv in cv_list:\n",
    "        cv_name = str(cv).partition(\"(\")[0]\n",
    "        print(cv_name)\n",
    "        cv_scores = []\n",
    "        for k in k_range:\n",
    "            score = cross_val_score(KNeighborsClassifier(n_neighbors=k), X_train, y_train, cv=cv, scoring='accuracy').mean()\n",
    "            # print(f\"{cv_name} score : {score}\")\n",
    "            cv_scores.append(score)\n",
    "\n",
    "        # Plot the graph\n",
    "        plt.plot(cv_scores, label=cv_name)\n",
    "\n",
    "        # Print\n",
    "        cv_scores_max = max(cv_scores)\n",
    "        cv_scores_min = min(cv_scores)\n",
    "        cv_scores_mean = mean(cv_scores)\n",
    "        cv_results[cv] = {'mean' : cv_scores_mean, 'min' : cv_scores_min, 'max' : cv_scores_max}\n",
    "        print(f\"- CV name : {cv_name} - CV mean : {cv_scores_mean} - CV min : {cv_scores_mean} - CV max : {cv_scores_max}\")\n",
    "\n",
    "        # Saving values\n",
    "        k_val=k_range[np.argmax(np.array(cv_scores))]\n",
    "        if cv_retenu==None or max_val_score<cv_scores_max :\n",
    "            cv_retenu=cv\n",
    "            max_val_score=cv_scores_max\n",
    "            k_retenu=k_val\n",
    "\n",
    "    # Show the graph\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # print(cv_results)\n",
    "    print(\"cv retenu : \", cv_retenu)\n",
    "    print(\"max_val_score : \", max_val_score)\n",
    "    print(\"k_retenu : \", k_retenu)\n",
    "\n",
    "    return cv_retenu, max_val_score, k_retenu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_list = [KFold(n_splits=4), LeaveOneOut(), ShuffleSplit(n_splits=4, train_size=0.8), StratifiedKFold(n_splits=4, shuffle=True)]\n",
    "\n",
    "# Chossing the best Cross-validation method\n",
    "cv_choice(cv_list, X_train_scaler, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "k = np.arange(1, 50)\n",
    "train_score, val_score = validation_curve(KNeighborsClassifier(), X_train_scaler, y_train, param_name='n_neighbors', param_range=k, cv=5)\n",
    "\n",
    "plt.plot(k, val_score.mean(axis=1), label=\"Validation\")\n",
    "plt.plot(k, train_score.mean(axis=1), label=\"Train\")\n",
    "plt.ylabel('score')\n",
    "plt.xlabel('n_neighbors')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_neighbors' : np.arange(1, 20), 'metric' : ['euclidean', 'manhattan']}\n",
    "\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)\n",
    "grid.fit(X_train_scaler, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afficher le meilleur score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afficher les paramètres donnant les meilleures performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegarder le meilleur modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model\n",
    "model_best = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tester le nouveau modèle sur les données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score du meilleur modèle\n",
    "model_best.score(X_test_scaler, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search CV Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_choice(model, param_grid, cv_list, X_train, y_train, X_test, y_test, k_range = range(1, 20)):\n",
    "\n",
    "    best_model = None\n",
    "    best_params = None\n",
    "    best_cv = None\n",
    "    best_cv_score = 0\n",
    "\n",
    "    for cv in cv_list:\n",
    "\n",
    "        cv_name = str(cv).partition(\"(\")[0]\n",
    "        print(cv_name)\n",
    "\n",
    "        grid = GridSearchCV(model, param_grid, cv=cv)\n",
    "        grid.fit(X_train, y_train)\n",
    "\n",
    "        # CV\n",
    "        grid_cv_score = grid.best_score_\n",
    "\n",
    "        print(f\"CV name : {cv_name} - CV score : {grid_cv_score}\")\n",
    "\n",
    "        # Saving values\n",
    "        if best_model==None or best_cv_score<grid_cv_score :\n",
    "            best_cv_score = grid_cv_score\n",
    "            best_model = grid.best_estimator_\n",
    "            best_params = grid.best_params_\n",
    "            best_cv = cv\n",
    "            best_model_test_score = grid.best_estimator_.score(X_test, y_test)\n",
    "\n",
    "    return best_model, best_params, best_model_test_score, best_cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold\n",
      "CV name : KFold - CV score : 0.9583333333333333\n",
      "LeaveOneOut\n",
      "CV name : LeaveOneOut - CV score : 0.9583333333333334\n",
      "ShuffleSplit\n",
      "CV name : ShuffleSplit - CV score : 0.96875\n",
      "StratifiedKFold\n",
      "CV name : StratifiedKFold - CV score : 0.9666666666666667\n",
      "Best model :  KNeighborsClassifier(metric='euclidean', n_neighbors=4)\n",
      "Best params :  {'metric': 'euclidean', 'n_neighbors': 4}\n",
      "Best CV :  ShuffleSplit(n_splits=4, random_state=None, test_size=None, train_size=0.8)\n",
      "Best model test score :  1.0\n"
     ]
    }
   ],
   "source": [
    "best_model, best_params, best_model_test_score, best_cv = grid_choice(KNeighborsClassifier(), {'n_neighbors' : np.arange(1, 20), 'metric' : ['euclidean', 'manhattan']}, cv_list, X_train_scaler, y_train, X_test_scaler, y_test)\n",
    "\n",
    "print(\"Best model : \", best_model)\n",
    "print(\"Best params : \", best_params)\n",
    "print(\"Best CV : \", best_cv)\n",
    "print(\"Best model test score : \", best_model_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = model_best.predict(X_test_scaler)\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'prediction': y_pred, 'actual': y_test}\n",
    "df = pd.DataFrame(data)\n",
    "contingency_matrix = pd.crosstab(df['prediction'], df['actual'])\n",
    "print(contingency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(contingency_matrix.T, annot=True, fmt='.2f', cmap=\"YlGnBu\", cbar=False)\n",
    "plt.title('Matrice de confusion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "N, train_score, val_score = learning_curve(model_best, X_train_scaler, y_train, train_sizes=np.linspace(0.1, 1.0, 10), cv=5)\n",
    "\n",
    "print(N)\n",
    "plt.plot(N, train_score.mean(axis=1), label='train')\n",
    "plt.plot(N, val_score.mean(axis=1), label='validation')\n",
    "plt.xlabel('train_sizes')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporter le modèle avec joblib ou Pickle. Il faut exporter :\n",
    "- Le modèle\n",
    "- Le scaler\n",
    "- le nom des colonnes X\n",
    "- les valeurs possibles de la 'target' (si catégorie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "dict_export = {}\n",
    "dict_export['model'] = model_best\n",
    "dict_export['scaler'] = scaler\n",
    "dict_export['X_col_names'] = X_col_names\n",
    "dict_export['y_names'] = list(iris.target_names)\n",
    "\n",
    "pickle_out = open(\"model.pkl\",\"wb\")\n",
    "pickle.dump(dict_export, pickle_out)\n",
    "pickle_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a537cdb13d7aeb39d11da608c8476043be259ee4aa207ebadd48cee87be9109"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
